<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Topic: Deployment Series | Vladi Gleba]]></title>
  <link href="http://vladigleba.github.io/blog/topics/deployment-series/atom.xml" rel="self"/>
  <link href="http://vladigleba.github.io/"/>
  <updated>2014-10-12T15:59:10-07:00</updated>
  <id>http://vladigleba.github.io/</id>
  <author>
    <name><![CDATA[Vladi Gleba]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 6: Writing Capistrano Tasks]]></title>
    <link href="http://vladigleba.github.io/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks/"/>
    <updated>2014-04-10T08:42:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks</id>
    <content type="html"><![CDATA[<p>It’s been a long time coming, but we finally reached the point where we can deploy our app to our VPS and have it be available on the internet for viewing. We configured Capistrano in the <a href="/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/">previous post</a>, and now we’ll actually use it for the deploy. Just like in the previous posts, I’ll be going over how I have things setup for <a href="http://phindee.com/">Phindee</a> to help illustrate the concepts.</p>

<!-- more -->


<p>You might already know this, but Capistrano does much of its work with the help of tasks. When we previously ran <code>cap install</code>, we actually invoked a task named <code>install</code> that created various files and directories; if you’re interested, you can see its code <a href="https://github.com/capistrano/capistrano/blob/master/lib/capistrano/tasks/install.rake">on GitHub</a>. Similarly, we can write our own tasks to help us automate various things.</p>

<p>When I was deploying Phindee, I created a file called <code>setup.rake</code> inside the app’s local <code>/lib/capistrano/tasks</code> directory. Go ahead and do the same for your app, and add the following code into it:</p>

<p>``` ruby setup.rake
namespace :setup do</p>

<p>  desc &ldquo;Upload database.yml file.&rdquo;
  task :upload_yml do</p>

<pre><code>on roles(:app) do
  execute "mkdir -p #{shared_path}/config"
  upload! StringIO.new(File.read("config/database.yml")), "#{shared_path}/config/database.yml"
end
</code></pre>

<p>  end</p>

<p>  desc &ldquo;Seed the database.&rdquo;
  task :seed_db do</p>

<pre><code>on roles(:app) do
  within "#{current_path}" do
    with rails_env: :production do
      execute :rake, "db:seed"
    end
  end
end
</code></pre>

<p>  end</p>

<p>  desc &ldquo;Symlinks config files for Nginx and Unicorn.&rdquo;
  task :symlink_config do</p>

<pre><code>on roles(:app) do
  execute "rm -f /etc/nginx/sites-enabled/default"

  execute "ln -nfs #{current_path}/config/nginx.conf /etc/nginx/sites-enabled/#{fetch(:application)}"
  execute "ln -nfs #{current_path}/config/unicorn_init.sh /etc/init.d/unicorn_#{fetch(:application)}"
</code></pre>

<p>   end
  end</p>

<p>end
```</p>

<p>The first thing you’ll notice is we’re organizing all of the tasks here under a namespace called <code>:setup</code>. It’s not strictly necessary, but I just like to keep things organized. If the code seems overwhelming, don’t worry&mdash;I’ll explain everything.</p>

<h1>Uploading Database Info</h1>

<p>We’ll get a feel for how tasks work and what they’re capable of doing by running the first task in this file, which will simply upload our <code>database.yml</code> file to our server. But before we run it, we first need to add <code>database.yml</code> to our <code>.gitignore</code> file to let Git know we don’t want it tracked and uploaded to GitHub from now on. Why? Because we’ll be adding our database password into it, and it’s generally not a good idea to upload passwords to your GitHub repository. Below is how my <code>.gitignore</code> file looks like (it&rsquo;s usually located in your app&rsquo;s root directory, but if it&rsquo;s not there, go ahead and create it):</p>

<p>``` text .gitignore</p>

<h1>Ignore bundler config.</h1>

<p>/.bundle</p>

<h1>Ignore the default SQLite database.</h1>

<p>/db/<em>.sqlite3
/db/</em>.sqlite3-journal</p>

<h1>Ignore log, doc, and tmp directories</h1>

<p>/log/*.log
/tmp
/doc</p>

<h1>Ignore .DS_Store files on Mac</h1>

<p>.DS_Store</p>

<h1>Ignore database.yml file to prevent password leakage</h1>

<p>/config/database.yml
```</p>

<p>You can see that in addition to ignoring the <code>database.yml</code> file, I’m also ignoring lots of other files as well, especially the annoying <code>.DS_Store</code> files that the Mac OS loves to create.</p>

<p>With that out of the way, we can now safely open up <code>database.yml</code> and add our database parameters to the file&rsquo;s production section. We’ll only need to modify the <code>database</code>, <code>username</code>, and <code>password</code> keys, and everything else can be left the way it is. Make sure you set these to the database name, username, and password you created in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>.</p>

<p>Then run the following command inside your app’s local root directory:</p>

<p><code>bash
cap production setup:upload_yml
</code></p>

<p>This tells Capistrano to execute the <code>upload_yml</code> task inside the <code>setup</code> namespace using the <code>production.rb</code> file configurations. (If we had the <code>stage.rb</code> file setup, we could’ve ran <code>cap stage setup:upload_yml</code> to execute this task on our staging environment instead.) We can verify that the command uploaded the <code>database.yml</code> file to our server by logging in and outputting the contents of the file:</p>

<p><code>bash
cat /var/www/phindee/shared/config/database.yml
</code></p>

<p>This is obviously a trivial task, but it shows how powerful Capistrano can be. A few keystrokes allowed us to create a specific directory structure on our server and upload a file from our local computer. Neat stuff&mdash;and it will only get better.</p>

<p>All right, let’s now switch gears and learn about the syntax that made all of this possible.</p>

<h1>Understanding SSHKit</h1>

<p>Capistrano 3 uses the Rake DSL (Domain Specific Language), which means if you ever wrote Rake tasks, you&rsquo;ll be in familiar territory when writing Capistrano tasks; the only new thing you&rsquo;ll need to learn about is SSHKit and the various methods it provides. <a href="https://github.com/capistrano/sshkit">SSHKit</a> was actually developed and released with Capistrano 3, and it’s basically a lower-level tool that provides methods for connecting and interacting with remote servers; it does all the heavy lifting for Capistrano, in other words. There are four main methods you need to know about:</p>

<ul>
<li><code>on()</code>: specifies the server to run on</li>
<li><code>within()</code>: specifies the directory path to run in</li>
<li><code>as()</code>: specifies the user to run as</li>
<li><code>with()</code>: specifies the environment variables to run with</li>
</ul>


<p>Typically, you’ll start a task by using an <code>on()</code> method to specify the server on which you want your commands to run. Then you can use any combination of <code>as()</code>, <code>within()</code>, and <code>with()</code> methods, which are repeatable and stackable in any order, to provide additional details. For example, the <code>upload_yml</code> task we ran in <code>setup.rake</code> uses the <code>on()</code> method to specify that the resulting block of code should only be run on the application server. The <code>seed_db</code> task right below it has <em>three</em> parameters that specify how the resulting statement will run; it uses <code>on()</code>, <code>within()</code>, and <code>with()</code> to specify that the statement should only run <em>on</em> the application server, <em>within</em> the path specified, and <em>with</em> certain environment variables set.</p>

<p>Obviously, if SSHKit gives you methods to specify certain parameters that must be met before the actual statements are run, it should also give you methods to help you run those statements. That’s exactly what it does, and below are those methods:</p>

<ul>
<li><code>execute()</code>: the workhorse that runs the commands on your server</li>
<li><code>upload()</code>: uploads a file from your local computer to your remote server</li>
<li><code>capture()</code>: executes a command and returns its output as a string</li>
<li><code>puts()</code>: writes the output returned by <code>capture()</code> to the screen</li>
<li><code>background()</code>: runs a command in the background</li>
<li><code>test()</code>: can be used for control flow since it works like the <code>test</code> command-line utility in Unix and returns false if its expression exits with a non-zero value</li>
</ul>


<p>Armed with this knowledge, we’re now better equipped to understand the three tasks in <code>setup.rake</code>.</p>

<h1>Task Walk-Through</h1>

<p>The <code>upload_yml</code> task, for example, is run on the application server only, and its first statement uses the <code>execute()</code> method to run <code>mkdir -p</code>, which creates the following directory structure inside <code>/var</code>, if it doesn’t already exist:</p>

<pre><code>├── www
  └── phindee
    └── shared
      └── config
</code></pre>

<p>The <code>shared_path</code> variable evaluates to <code>/var/www/phindee/shared</code>, since it takes the path we specified in <code>deploy_to</code> and appends the <code>/shared</code> directory to the end of it (<a href="https://github.com/capistrano/capistrano/blob/aeab6b6a1e5c5e654f35321dcd7438a0659864d0/lib/capistrano/dsl/paths.rb#L60">see the code</a>). We then append the <code>/config</code> directory to the end of that.</p>

<p>The next statement uses <code>upload()</code> to upload our <code>database.yml</code> file to the directory we just created above. <code>File.read()</code> returns the file&rsquo;s contents as a string, which <code>StringIO.new()</code> takes and turns into a file. We then use this file as our source and <code>#{shared_path}/config/database.yml</code> as our destination. By the way, <code>upload()</code> has the bang symbol (!) because that’s how it’s defined in SSHKit, and it&rsquo;s just a convention letting us know that the method will block until it finishes.</p>

<p>The <code>seed_db</code> task does exactly what it says&mdash;seeds the database with data by running <code>rake db:seed</code>. The <code>current_path</code> variable takes the <code>deploy_to</code> path and appends <code>/current</code> to it, which will result in <code>/var/www/phindee/current</code>. This is where the seed statement will run on the application server with the <code>rails_env</code> variable set to <code>:production</code>.</p>

<p>But in order to ensure <code>rake</code> runs with the proper environment variables set, we have to use <code>rake</code> as a symbol and pass <code>db:seed</code> as a string; otherwise, the environment variables won&rsquo;t be set. This format will also be necessary whenever you’re running any other Rails-specific commands that rely on certain environment variables being set (see <a href="https://github.com/capistrano/sshkit#the-command-map">this section</a> of the SSHKit README to learn more).</p>

<p>The final <code>:symlink_config</code> task does a couple ofthings. First, it removes the default configuration file for Nginx (<code>/etc/nginx/sites-enabled/default</code>) and replaces it with a symlink to our own configuration file (<code>nginx.conf</code>). Then it also creates a symlink to our <code>unicorn_init.sh</code> script that helps us manage Unicorn, but this time inside <code>/etc/init.d</code>, which is the place where Ubuntu stores scripts for managing various services (a similar script for managing Nginx was already added there when we ran <code>apt-get</code>). Notice we’re using <code>fetch()</code> in both cases, which simply retrieves the value of a variable initialized by <code>set()</code>, to name our files after our application name.</p>

<p>These three tasks just merely scratch the surface of what’s possible, however. I recommend you take a look at SSHKit’s <a href="https://github.com/capistrano/sshkit/blob/master/EXAMPLES.md">example page</a> to learn more; I found it to be an invaluable tool in helping me better understand how all the different methods work together.</p>

<h1>Finishing Touches</h1>

<p>We’re almost ready for our deploy. There’s just one more file we need to add to <code>/lib/capistrano/tasks</code> called <code>deploy.rake</code>. Below is the code I have in mine:</p>

<p>``` ruby deploy.rake
namespace :deploy do</p>

<p>  desc &ldquo;Makes sure local git is in sync with remote.&rdquo;
  task :check_revision do</p>

<pre><code>unless `git rev-parse HEAD` == `git rev-parse origin/master`
  puts "WARNING: HEAD is not the same as origin/master"
  puts "Run `git push` to sync changes."
  exit
end
</code></pre>

<p>  end</p>

<p>  %w[start stop restart].each do |command|</p>

<pre><code>desc "#{command} Unicorn server."
task command do
  on roles(:app) do
    execute "/etc/init.d/unicorn_#{fetch(:application)} #{command}"
  end
end
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>The <code>check_revision</code> task checks to make sure we pushed all our local changes to the remote master branch; if it finds that our local code is out of sync with the remote, the <code>exit</code> statement will cause Capistrano to quit. We&rsquo;ll want to run this task <em>before</em> Capistrano runs its own <code>deploy</code> task to make sure we don’t forget to push our local changes up to GitHub when trying to deploy.</p>

<p>The second block of code actually creates <em>three</em> separate tasks that will allow us to start, stop, and restart Unicorn from our local computer. We&rsquo;ll run the <code>restart</code> task, for example, after Capistrano finishes its deploy so Unicorn picks up the new code. (Note that I created a namespace called <code>deploy</code> to contain these tasks since that&rsquo;s what they&rsquo;re related to.)</p>

<p>But how do we tell Capistrano to run these tasks as part of its deploy? Well, Capistrano provides two callback functions called <code>before()</code> and <code>after()</code> to help us out, and the code below illustrates how it&rsquo;s done (add it to the end of your <code>deploy.rake</code> file):</p>

<p>``` ruby deploy.rake
namespace :deploy do</p>

<p>  &hellip;</p>

<p>  before :deploy, &ldquo;deploy:check_revision&rdquo;
  after :deploy, &ldquo;deploy:restart&rdquo;
  after :rollback, &ldquo;deploy:restart&rdquo;
end
```</p>

<p>We&rsquo;re first using <code>before()</code> to tell Capistrano to run our <code>check_revision</code> task before it runs its own <code>deploy</code> task. Then we use <code>after()</code> to make sure Capistrano restarts Unicorn after a <code>deploy</code>. Finally, we do the same thing after a <code>rollback</code> task, which is a task that simply allows you to rollback to the previous deploy if you don&rsquo;t like the current one, for whatever reason, and it&rsquo;s invoked by running <code>cap production deploy:rollback</code>. Of course, we could use these callbacks with <em>any</em> task to run <em>any other</em> task, and this is powerful because it allows us to reuse and extend our code in different ways.</p>

<p>I&rsquo;d like to point out that we&rsquo;re using the callbacks inside a namespace to make sure Capistrano knows which tasks the callbacks are referencing. This way Capistrano will know to run the <code>deploy</code> task, for example, that&rsquo;s defined in its own <code>deploy</code> namespace, and not some other task with an identical name defined somewhere else.</p>

<p>What we now have is our own custom recipe (a Capistrano term meaning a series of tasks) for deployment. You can similarly write multiple other recipes to help you automate any other tedious work you find yourself doing over and over again.</p>

<p>All right, having all the necessary tasks defined, we can go ahead and push our code up to GitHub so Capistrano can deploy the latest changes:</p>

<p><code>bash
git add .
git commit -m "message"
git push origin master
</code></p>

<p>We’re now ready to deploy.</p>

<h1>Show Time</h1>

<p>This is a moment that was a long time coming. Let’s see what happens:</p>

<p><code>bash
cap production deploy
</code></p>

<p>It&rsquo;s likely that you encountered some type of error before the task was able to finish. This is normal&mdash;something always goes wrong the first time you deploy (if everything went smoothly, on the other hand, you deserve a place in the Capistrano hall of fame). Capistrano configurations are specific to your setup/environment, and what worked for me may not necessarily work for you. The best advice I can give is to google the specific problem you’re having, and it’s likely you&rsquo;ll find someone who struggled with the same thing and already provided a possible solution for you.</p>

<h2>Breaking It Down</h2>

<p>A lot of things happened when we ran <code>cap production deploy</code>. If you do an <code>ls</code> on your <code>deploy_to</code> directory, for example, you’ll find four new directories there:</p>

<ul>
<li><code>/releases</code>: whenever you deploy, a new directory will be created here containing all the code for that deploy</li>
<li><code>/current</code>: a symlink pointing to the latest directory in <code>/releases</code></li>
<li><code>/shared</code>: holds files and directories that persist throughout deploys</li>
<li><code>/repo</code>: contains a clone of your <code>.git</code> repo</li>
</ul>


<p>With regards to the directories in <code>/shared</code>, the main ones you need to know about are:</p>

<ul>
<li><code>/config</code>: contains our <code>database.yml</code> file</li>
<li><code>/log</code>: contains the <code>production.log</code> and <code>unicorn.log</code> files (see <code>/var/log/nginx/error.log</code> for the Nginx log file)</li>
<li><code>/public/assets</code>: contains all your assets</li>
<li><code>/tmp/pids</code>: will contain a <code>unicorn.pid</code> file that stores the process ID of Unicorn’s master process (when it&rsquo;s running)</li>
</ul>


<p>When you run <code>cap production deploy</code>, you’re actually calling a Capistrano task called <code>deploy</code>, which then sequentially invokes other tasks. The main ones are listed below:</p>

<ol>
<li><code>starting</code>: creates the directory structure and checks that the GitHub repository is reachable</li>
<li><code>updating</code>: copies the GitHub repository to a new <code>/releases</code> directory, adds symlinks pointing to <code>/shared</code>, runs Bundler, runs migrations, and compiles assets</li>
<li><code>publishing</code>: symlinks the <code>/current</code> directory to the new <code>/releases</code> directory</li>
<li><code>finishing</code>: removes old <code>/releases</code> directories</li>
</ol>


<p>If you run <code>cap -T</code>, you’ll see all these tasks listed, along with some other tasks that Capistrano runs during a deploy (see the <a href="http://capistranorb.com/documentation/getting-started/flow/">documentation</a> to learn when they&rsquo;re run). The tasks we defined ourselves will also be listed there, along with their descriptions.</p>

<p>Now that our code is deployed, we can run the two other tasks in <code>deploy.rb</code>. If you have a seed file for seeding your database, you can run <code>cap production setup:seed_db</code> to invoke it; otherwise, you&rsquo;ll need to run <code>cap production setup:symlink_config</code> to symlink your config files.</p>

<h1>Wrapping Up</h1>

<p>One last thing we have left to do is add our symlinked Unicorn script (the one in <code>/etc/init.d</code>) to Ubunut’s startup scripts to make sure Unicorn will automatically start up whenever we restart our VPS. We can do this easily using the <code>update-rc.d</code> utility; we just need to give it a name of a file in <code>/etc/init.d</code>, and it&rsquo;ll automatically add it to the correct startup folders. Below is the command that does this (be sure to change <code>unicorn_phindee</code> to the name of your own script):</p>

<p><code>bash
sudo update-rc.d unicorn_phindee defaults
</code></p>

<p>This was already done automatically, by the way, for Nginx and PostgreSQL when we installed them with <code>apt-get</code> in part 2, which means that whenever we restart our VPS, these services will be restarted automatically as well.</p>

<p>Once that’s done, I’ll log in to my VPS and restart Nginx (so it picks up the <code>nginx.conf</code> file we symlinked). Then I’ll start Unicorn by calling <code>start</code> on the <code>unicorn_phindee</code> script (be sure to use your own file name):</p>

<p><code>bash
sudo service nginx restart
/etc/init.d/unicorn_phindee start
</code></p>

<p>If you now open up your favorite browser (I hope it&rsquo;s not Internet Explorer) and type your server’s IP address into the address bar, you might see your app; if you you don&rsquo;t, don&rsquo;t worry. Deployment is hard and takes a while to sink in. If things aren’t working, your best bet is to start with the logs and google any errors you find there.</p>

<p>But the most important thing is to not get discouraged. When I set up my production server from scratch for the very first time, it took me a <em>full week</em> (I’m not kidding) to get it working. It was frustrating, discouraging, and is the reason why I decided to write this series, because I didn’t want other people going through the same thing. It doesn&rsquo;t have be that way though, and I hope it won&rsquo;t be.</p>

<p>(If you enjoyed this series, you might also like the <a href="/blog/topics/chef-series/">&ldquo;Provisioning a Rails Server Using Chef&rdquo; series</a>, which explains how you can use Chef to automate your entire server setup.)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 5: Configuring Capistrano]]></title>
    <link href="http://vladigleba.github.io/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/"/>
    <updated>2014-04-04T07:36:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano</id>
    <content type="html"><![CDATA[<p>In the previous four posts, I covered how I went about setting up my server for Phindee and how I configured Unicorn and Nginx. Here in part 5, I will now talk about how I configured Capistrano to actually deploy Phindee.</p>

<!-- more -->


<p>If you’re not familiar with it, <a href="http://capistranorb.com/">Capistrano</a> is the de-facto deployment tool for Rails apps; it makes deployment easier by automating a lot of the work for you, and it can be easily customized to suit your particular needs. If you’ve never used it before, I hope this post will give you a taste of what it can do.</p>

<p>By the way, I’ll be using version 3, which came out last summer; it’s a complete rewrite that ended up reducing Capistrano’s footprint to just 700 lines of code! If you’re coming from version 2, I recommend reading <a href="https://semaphoreapp.com/blog/2013/11/26/capistrano-3-upgrade-guide.html">this post</a> to learn about the differences.</p>

<p>One of the ways the core team was able to keep it so lean was by breaking framework-specific tasks into separate gems, which means that in addition to installing the Capistrano gem itself, we’ll need to install Rails-specific gems as well. Here is what you should add to your <code>Gemfile</code>:</p>

<p>``` ruby Gemfile
&hellip;</p>

<p>group :development do
  gem &lsquo;capistrano&rsquo;, &lsquo;~> 3.2.1&rsquo;
  gem &lsquo;capistrano-rails&rsquo;, &lsquo;~> 1.1.1&rsquo;
  gem &lsquo;capistrano-bundler&rsquo;, &lsquo;~> 1.1.2&rsquo;
  gem &lsquo;capistrano-rbenv&rsquo;, &lsquo;~> 2.0.2&rsquo;
end
```</p>

<p>Since we’ll only be using Capistrano in development, we put all the gems in the <code>:development</code> group. Note that we added Rails-specific tasks through the <code>capistrano-rails</code> gem, Bundler-specific tasks through the <code>capistrano-bundler</code> gem, and rbenv-specific tasks through the <code>capistrano-rbenv</code> gem.</p>

<p>We can install them by running <code>bundle</code> in the root directory of our Rails app. After Bundler finishes the install, we’ll tell Capistrano to create the necessary files it needs to do its job by running the following:</p>

<p><code>bash
cap install
</code></p>

<p>One of the files this created is called <code>Capfile</code>, which will be located in the root directory of your Rails app. It&rsquo;ll contain various <code>require</code> statements to load the necessary code that Capistrano will need to do its job. We’ll open it up and uncomment the following lines to load the gems we just installed:</p>

<p><code>ruby Capfile
require 'capistrano/rails'
require 'capistrano/bundler'
require 'capistrano/rbenv'
</code></p>

<p>You’ll also see the following line at the end of the file:</p>

<p><code>ruby Capfile
Dir.glob('lib/capistrano/tasks/*.rake').each { |r| import r }
</code></p>

<p>This will load any custom tasks from <code>lib/capistrano/tasks</code>, which we will later define.</p>

<h1>Roll up Your Sleeves</h1>

<p>One cool thing about Capistrano is it’s designed to work with different deployment scenarios. You could, for example, have both a production server running your “live” application and a staging server meant for testing newly developed features before they’re pushed to the production server. In other words, you’d have two deployment stages: production and staging. When we ran <code>cap install</code>, Capistrano actually already created the necessary files for this; they’re located inside the <code>/config/deploy</code> directory and are named <code>production.rb</code> and <code>staging.rb</code>, respectively. We’ll use them to define stage-specific configurations, while configurations that are meant to be shared across all stages will be set in <code>config/deploy.rb</code>, and that’s where we’ll start first.</p>

<h2>General Configuration</h2>

<p>Below is how my <code>deploy.rb</code> file looks like for Phindee:</p>

<p>``` ruby deploy.rb
lock &ldquo;3.2.1&rdquo;</p>

<p>set :application, &ldquo;phindee&rdquo;
set :repo_url, &ldquo;git@github.com:vladigleba/phindee.git&rdquo;</p>

<p>set :deploy_to, &ldquo;/var/www/#{fetch(:application}&rdquo;
set :deploy_user, &ldquo;bob&rdquo;</p>

<p>set :rbenv_type, :user # or :system, depends on your rbenv setup
set :rbenv_ruby, &ldquo;2.1.0&rdquo;
set :rbenv_prefix, &ldquo;RBENV_ROOT=#{fetch(:rbenv_path)} RBENV_VERSION=#{fetch(:rbenv_ruby)} #{fetch(:rbenv_path)}/bin/rbenv exec&rdquo;
set :rbenv_map_bins, %w{rake gem bundle ruby rails}
set :rbenv_roles, :all # default value</p>

<p>set :linked_files, %w{config/database.yml}
set :linked_dirs, %w{bin log tmp/pids tmp/cache tmp/sockets vendor/bundle public/system}</p>

<p>set :keep_releases, 5
```</p>

<p>The very first line locks the configurations in this file to Capistrano 3.1, and if you have any other version installed, the file won’t run. (This is designed to help prevent configurations from braking between version updates.)</p>

<p>Next, we’re using the <code>set()</code> function to initialize the <code>:application</code> variable to “phindee.” (We’ll retrieve this variable’s value later using the corresponding <code>fetch()</code> function.) We’re also setting the <code>:repo_url</code> variable to the URL of the GitHub repository containing your code so Capistrano  knows where to look when we deploy. By the way, if your code is on a branch other than “master,” you’ll need to specify its name by adding <code>set :branch, “branch-name”</code>; otherwise, this is not needed because Capistrano sets it to “master” by default.</p>

<p>The next line sets the <code>:deploy_to</code> variable to the path where you want Capistrano storing the code it downloads from GitHub. This should be the same path you previously set in <code>unicorn.rb</code>, but without the <code>/current</code> directory appended to it. This is because <code>/current</code> represents the directory with the latest deploy code, while Capistrano is interested in the general app directory.</p>

<p><code>:deploy_user</code> is then set to the user Capistrano will be deploying as, and this should match the user you created when you setup your server in <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>.</p>

<p>The next few lines set variables needed by rbenv, and I actually copied and pasted these lines from the <code>capistrano-rbenv</code> <a href="https://github.com/capistrano/rbenv">README file</a>. The key variable here is <code>:rbenv_ruby</code>, which sets the Ruby version that rbenv installed on your machine, and you can run <code>ls ~/.rbenv/versions</code> in the command line to find which version that is. If this is not set correctly, the deploy will fail.</p>

<p>The other variable worth mentioning here is <code>:rbenv_type</code>. We could set it to <code>:system</code> if rbenv was installed system-wide on our machine, but since we installed rbenv on a per-user basis inside <code>~/.rbenv</code>, we&rsquo;re setting it to <code>:user</code>. System-wide installs can lead to problems with permissions, and it’s generally cleaner to just do a per-user install. The other three variables don’t need to be modified, and you can leave them the way they are.</p>

<p>Moving on, we’re setting the <code>:linked_files</code> variable to an array of strings initialized to <code>config/database.yml</code>. This tells Capistrano to store our app’s <code>config/database.yml</code> file inside a directory called <code>/shared</code>, which is meant for any files we want to persist between deploys. Since the contents of <code>database.yml</code> won’t change between deploys, it’s a good idea to store it there.</p>

<p>Similarly, <code>:linked_dirs</code> contains <em>directories</em> that are meant to persist between deploys, and they too will be stored inside <code>/shared</code>. These include directories containing things like log files, Unicorn sockets, and <code>.pid</code> files that will all stay the same between deploys.</p>

<p>And finally, <code>:keep_releases</code> tells Capistrano to only keep the last 5 deploys and discard everything else. This can be useful whenever you need to rollback to a previous release, but you also don&rsquo;t want releases piling up, so it&rsquo;s best not to set this number too high.</p>

<h2>Stage-Specific Configuration</h2>

<p>Now that <code>deploy.rb</code> is configured, we’ll move on to defining stage-specific configurations. Since I currently don’t have a separate environment for staging, I’ll only be going over the <code>config/deploy/production.rb</code> file, and you can just leave <code>staging.rb</code> the way it is by default. Below is how my <code>production.rb</code> file looks like:</p>

<p>``` ruby production.rb
set :stage, :production
set :rails_env, :production</p>

<p>server &lsquo;xxx.xxx.xxx.xxx&rsquo;, user: &lsquo;bob&rsquo;, port: 12345, roles: %w{web app db}, primary: true
```</p>

<p>As you can see, there isn’t much going on here. We’re first setting the <code>:stage</code> variable to <code>:production</code> to let Capistrano know that this file is meant for production. We’re also setting the <code>:rails_env</code> variable to the same thing to make sure Rails runs in the production environment. But the key line is the last line, which tells Capistrano how to access our VPS server. Make sure you replace the Xs with the IP address of the server you setup in part 1, along with the user and port number it&rsquo;s set up with.</p>

<p>We’re then using the <code>:roles</code> variable to let Capistrano know that our database server (PostgreSQL) represented by <code>db</code>, web server (Nginx) represented by <code>web</code>, and application server (Unicorn) represented by <code>app</code> all run on the same machine. Apps with lots of traffic, on the other hand, might have multiple separate physical servers for each of these. Setting <code>:primary</code> to <code>true</code> then tells Capistrano that this is our primary database server, and Capistrano will run migrations only on the one we designate as <code>:primary</code>. Even if we’re running all our servers on the same physical machine, setting <code>:primary</code> is still necessary.</p>

<h1>Enabling Agent Forwarding</h1>

<p>Now that Capistrano knows how to access our VPS, we need to make sure it can also access our code on GitHub. We’ll be using agent forwarding to allow us to reuse the local key we generated in part 1 to authenticate with GitHub. In order for this to work, we’ll need to add the key to GitHub, and you can do so by following step 3 on <a href="https://help.github.com/articles/generating-ssh-keys#step-3-add-your-ssh-key-to-github">this GitHub page</a>.</p>

<p>To enable agent forwarding in Capistrano 2, you had explicitly set it in <code>deploy.rb</code>, but in Capistrano 3, it’s already taken care of and enabled by default. The only thing we have left to do is log in to our VPS and run the following command to add github.com to the list of known hosts; this ensures Capistrano won’t have any problems with it being unknown when it tries downloading your code from GitHub to your server:</p>

<p><code>bash
ssh git@github.com
</code></p>

<p>You’ll get a warning asking if you’re sure you want to continue connecting. Verify that the key fingerprint matches the one you just added to GitHub, and enter “yes”. If you get an “access denied” message, see <a href="https://help.github.com/articles/error-permission-denied-publickey">this page</a> for potential solutions. If you’re experiencing some other agent forwarding problems, <a href="https://help.github.com/articles/using-ssh-agent-forwarding#troubleshooting">this page</a> might help you out.</p>

<h1>Setting Permissions</h1>

<p>If you look at <code>deploy.rb</code>, you’ll notice I set the <code>:deploy_to</code> variable to “/var/www/phindee,” but on my VPS, the <code>/var</code> directory doesn’t yet contain the <code>/www</code> directory. That’s not a problem since Capistrano will create it for me through the user <code>bob</code>, as specified in <code>deploy.rb</code>, but it needs write permissions to do so.</p>

<p>If you read <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>, you’ll remember we created a group called <code>deployers</code> to contain users with deployment privileges and added the user <code>bob</code> into it. This means we can give the necessary permissions <code>bob</code> will need by simply giving them to <code>deployers</code>, and since <code>bob</code> is a member of the group, he will automatically inherit them.</p>

<p>I’m already logged in to my VPS as <code>bob</code>, and I can change the <code>/var</code> directory’s group to <code>deployers</code> with the following command:</p>

<p><code>bash
sudo chgrp deployers /var
</code></p>

<p>We can then give this group write permissions so its members can create directories within <code>/var</code>:</p>

<p><code>bash
sudo chmod g+w /var
</code></p>

<p>There are two other places where we need to repeat this process. The first is the <code>/etc/nginx/sites-enabled</code> directory, which Nginx uses to store its configuration files, and this is where our <code>config/nginx.conf</code> file that we created in <a href="/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/">part 4</a> will go. But we actually won’t be storing the file itself there; we’ll create a symlink to it, instead. This will make our deploys easier to manage because we won’t need to add our <code>nginx.conf</code> file to the <code>/etc/nginx/sites-enabled</code> directory <em>every</em> time we deploy. We can simply symlink it since Capistrano will always store our latest deploy code in the same place (<code>/var/www/phindee/current</code>).</p>

<p>Same thing is needed for the <code>config/unicorn_init.sh</code> file from <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>. We’ll need to create a symlink inside <code>/etc/init.d</code>, since that’s the directory Linux uses to store all the shell scripts used to manage the various services installed on the system. When we installed Nginx in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, for example, a shell script was automatically installed there to help us manage Nginx, and it will be invoked whenever we run a command like <code>sudo service nginx restart</code>. There is nothing like this for Unicorn yet, which is why we need to create a symlink to our <code>unicorn_init.sh</code> script to give us similar functionality.</p>

<p>In order for Capistrano to create symlinks, it needs write permissions in the relevant directories. We can give them with the following commands:</p>

<p>``` bash
sudo chgrp deployers /etc/nginx/sites-enabled
sudo chmod g+w /etc/nginx/sites-enabled</p>

<p>sudo chgrp deployers /etc/init.d
sudo chmod g+w /etc/init.d
```</p>

<p>And now Capistrano should have the necessary permissions to do its work.</p>

<p>Having Capistrano configured, we’re ready to move on and start writing custom tasks to help us deploy our code, and that’s exactly what we’ll do in the <a href="/blog/2014/04/10/deploying-rails-apps-part-6-writing-capistrano-tasks/">next and last post</a> of this series. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you&rsquo;ll get it delivered to your inbox as soon as it’s released.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 4: Configuring Nginx]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/"/>
    <updated>2014-03-27T12:50:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx</id>
    <content type="html"><![CDATA[<p>I talked about how I configured Unicorn for <a href="http://phindee.com/">Phindee</a> in <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>, and now I&rsquo;ll cover how I configured Nginx. While Unicorn will handle requests for pages dynamically generated by Rails, Nginx will handle requests for static assets, like stylesheets, scripts, images, and fonts. If you’re wondering why I chose Nginx over Apache, see <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a> for the explanation.</p>

<!-- more -->


<p>All right, since there is quite a bit to cover, we’ll jump right in. We’ll start by creating a file called <code>nginx.conf</code> inside our app’s <code>/config</code> directory on our local computer. Here’s how mine looks like:</p>

<p>``` nginx nginx.conf
upstream unicorn {
  server unix:/tmp/unicorn.phindee.sock fail_timeout=0;
}</p>

<p>server {
  server_name www.phindee.com;
  return 301 $scheme://phindee.com$request_uri;
}</p>

<p>server {
  listen 80 default deferred;
  server_name phindee.com;
  root /var/www/phindee/current/public;</p>

<p> location ^~ /assets/ {</p>

<pre><code>gzip_static on;
expires max;
add_header Cache-Control public;
</code></pre>

<p>  }</p>

<p>  try_files $uri/index.html $uri @unicorn;
  location @unicorn {</p>

<pre><code>proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header Host $http_host;
proxy_redirect off;
proxy_pass http://unicorn;
</code></pre>

<p>  }</p>

<p>  error_page 500 502 503 504 /500.html;
  keepalive_timeout 10;
}
```</p>

<p>Nginx has a master process managing all the workers, just like Unicorn, which are responsible for processing requests from clients. Unlike Unicorn, Nginx also has a cache loader process that checks and/or populates the cache with metadata, as well a cache manager process that’s responsible for cache expiration. Together, they keep Nginx internals running quickly and efficiently.</p>

<h1>A Bit on Workers</h1>

<p>If you log in to your VPS and <code>cd</code> into <code>/etc/nginx</code>, you&rsquo;ll find a file called <code>nginx.conf</code>. This is the main Nginx configuration file that Nginx will parse when it runs, and it&rsquo;s the place where you can modify the number of workers available to process requests. You can do this by modifying the <code>worker_processes</code> directive defined at the top of the file. It&rsquo;s set to four workers by default, but I changed mine to one because that&rsquo;s more than enough for a low-traffic app. It&rsquo;s also possible to modify the number of connections a worker can accept by modifying the <code>worker_connections</code> directive inside the <code>events</code> block; I changed mine to 1024 connections.</p>

<p>This means that given our current configuration, our server will be able to accept a total of 1024 simultaneous connections. If you want to increase this, it’s generally best to increase the <code>worker_connections</code> value before increasing the number of workers. (Remember, each worker is a single-threaded process, so whenever you increase the number of workers, you’re also increasing the total amount of memory that will be used.) But having one worker process that’s capable of handling 1024 connections is more than enough for a low-traffic app.</p>

<p>By the way, if you&rsquo;re wondering how our own <code>nginx.conf</code> file we created above will get executed, <code>/etc/nginx/nginx.conf</code> already has an <code>include</code> directive inside the <code>http</code> block that will automatically include any files in the <code>/etc/nginx/sites-enabled</code> directory, and that&rsquo;s the place where we will put our own <code>nginx.conf</code> file when it&rsquo;s time to deploy.</p>

<h1>Hooking up with Unicorn and Handling Redirects</h1>

<p>Since Nginx is not capable of handling requests for pages that are dynamically generated by Rails, we need to tell it to somehow pass such requests off to Unicorn. We’ll take the first step to accomplishing this by defining an <code>upstream</code> block called <code>unicorn</code>, inside which we point the server to the same Unix socket that we used in our <code>unicorn.rb</code> file from <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">part 3</a>. This is just the first step, however, and more work needs to be done to get this working, as you’ll see later. By the way, in case you’re wondering, setting <code>fail_timeout</code> to 0 is necessary for Nginx to correctly handle Unicorn timing out due to its worker being killed when it takes longer than 30 seconds to respond, as specified in <code>unicorn.rb</code>.</p>

<p>The <code>server</code> block right below the <code>upstream</code> block is there to redirect a request for &ldquo;www.phindee.com&rdquo; to &ldquo;phindee.com&rdquo;. The <code>server_name</code> directive specifies the URL we’re redirecting from, while the <code>return</code> directive specifies where to redirect to. (Notice we’re returning a 301 status code to specify a permanent redirection.) The <code>$scheme</code> variable stores the HTTP scheme (i.e. http, https), while <code>$request_uri</code> stores the unmodified URI of a client request, which includes the arguments, but not the host name (e.g. &ldquo;/foo/bar.php?arg=baz&rdquo;).</p>

<h1>Where the Meat Is</h1>

<p>The next <code>server</code> block contains the main configuration. The <code>listen</code> directive inside it tells Nginx to listen on port 80, and the <code>server_name</code> directive right below specifies the domain name that Nginx will try to match, which is &ldquo;phindee.com&rdquo; in my case.</p>

<p>Specifying <code>default</code> in the <code>listen</code> directive, by the way, tells Nginx to use this server block by default if it can’t find a matching domain name, which means I could technically leave out the <code>server_name</code> directive completely, and everything would still work because of <code>default</code>, but I like to leave it in for readability. And finally, I added the <code>deferred</code> option since I’m running this on Linux, which tells Nginx to use the <code>TCP_DEFER_ACCEPT</code> option to <a href="http://www.techrepublic.com/article/take-advantage-of-tcp-ip-options-to-optimize-data-transmission/">speed up performance</a> by reducing the amount of preliminary work that happens between a client and the server.</p>

<p>Moving along, the <code>root</code> directive specifies the directory in which Nginx will look to handle requests for static files. This is basically the directory we specified inside <code>unicorn.rb</code>, except it has an additional <code>/public</code> directory appended to the end of it. It corresponds to your app’s <code>/public</code> directory on your local computer and is the place where your static files are and will reside. Currently, it only contains various error pages, a favicon, and a <code>robots.txt</code> file for search engines. When we later deploy with Capistrano, it’ll contain all our assets as well, including stylesheets, scripts, images, and fonts.</p>

<h1>Handling Asset Requests</h1>

<p>Just like the <code>server_name</code> directive handles requests for domain names, the <code>location</code> directive handles requests for specific files and folders. The caret and tilde (^~) tells Nginx to do a regular expression match on <code>/assets/</code> and to stop searching as soon as it finds a match (see the <a href="https://library.linode.com/web-servers/nginx/configuration/basic#sph_location-file-and-folder-configuration">Linode Guide</a> to learn more).</p>

<p>By setting the <code>gzip_static</code> directive to <code>on</code>, we’re then telling Nginx to look for an already pre-compressed <code>.gz</code> file <em>before</em> proceeding to compress it. This prevents Nginx from compressing the same file each time it is requested.</p>

<p>The <code>expires</code> directive then makes the response cacheable and marks it with an expiry date set to <code>max</code>, which is equivalent to December 31st, 2037. This tells browsers and any caching servers to not request these assets again until the specified date. Of course, if we make changes to our stylesheets, for example, Rails will change the filename and browsers will still receive the latest version, which will then also be cached.</p>

<p>Using the <code>expires</code> directive, however, is an outdated method of specifying caching, and it’s recommended to use <code>Cache-Control</code> header instead. The next line in the code does just that through the <code>add_header</code> directive. (The reason we include  <code>expires</code> is to make things backward-compatible.) It’s possible, by the way, to set <code>Cache-Control</code> to either <code>public</code> or <code>private</code>, and I’m setting it to <code>public</code> because we’re caching assets that are meant to be used by everybody, whereas <code>private</code> would mean they’re unique to individual users (see <a href="http://stackoverflow.com/questions/3492319/private-vs-public-in-cache-control">Stack Overflow</a> to learn more).</p>

<h1>Trying to Find a Match</h1>

<p>The next line is the <code>try_files</code> directive, which is there for requests that didn’t match with any <code>location</code> blocks. In our case, it tries to match non-asset requests. The <code>$uri</code> variable inside it contains the current request URI, minus the arguments, protocol, and host name, so if we typed in &ldquo;phindee.com/foobar&rdquo; into the address bar, the <code>$uri</code> would be &ldquo;/foobar&rdquo;, and given our <code>try_files</code> directive, Nginx would try to first match a <code>var/www/phindee/current/public/foobar/index.html</code> file. If it found no such file, it would then try to match the <code>/foobar</code> directory itself, and if that didn’t work, it would then pass the request off to Unicorn through a named location, which is defined next through the <code>location</code> directive and called <code>@unicorn</code>.</p>

<p>Inside the named location, the <code>proxy_pass</code> directive does all the heavy lifting. We set it to <code>http://unicorn</code> so that it points to the <code>upstream</code> block called <code>unicorn</code>, which we already defined, and the request is then handled by the Unicorn socket defined there. The two <code>proxy_set_header</code> directives then append additional headers needed for Unicorn, while <code>proxy_redirect</code> set to <code>off</code> prevents Nginx from doing any redirect handling. (There is a sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file on GitHub</a> with comments explaining why this is necessary.)</p>

<h1>Last Few Lines</h1>

<p>All right, we’re down to the last two lines. <code>error_page</code> makes sure that our app’s <code>500.html</code> page is shown for any 500-related errors, while <code>keepalive_timeout</code> tells Nginx to retain keep-alive connections (also known as persistent connections) for up to 10 seconds and close them if they exceed that time. The main concern when choosing the amount of time is mobile devices on slow networks, but I think 10 seconds should be enough.</p>

<p>Keep-alive connections, by the way, send multiple HTTP requests in a single connection, as opposed to opening a new connection for each request; in HTTP 1.1, all connections are persistent by default, which means stylesheets, scripts, images, and fonts, for example, would all be sent using a single connection.</p>

<p>These are, of course, not all the options you can specify. If you’d like to learn about the additional ones, feel free to read through the comments in the sample <code>nginx.conf</code> <a href="https://github.com/defunkt/unicorn/blob/master/examples/nginx.conf">file</a> I mentioned earlier.</p>

<p>And that wraps up part 4. I will introduce Capistrano in the <a href="/blog/2014/04/04/deploying-rails-apps-part-5-configuring-capistrano/">next post</a> and will explain how I configured it for Phindee. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you&rsquo;ll get it delivered to your inbox as soon as it’s released.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 3: Configuring Unicorn]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/"/>
    <updated>2014-03-21T10:08:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn</id>
    <content type="html"><![CDATA[<p>Having covered how to install the technology stack powering Phindee in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, I will now shift gears and talk about how I configured Unicorn. I already explained why I chose to install Nginx, but I haven’t yet explained why I chose Unicorn, so here we go.</p>

<!-- more -->


<p><a href="http://unicorn.bogomips.org/">Unicorn</a> is an HTTP server for Ruby. It&rsquo;s designed to be used in a production environment, unlike WEBrick, which is designed for running your app on your local computer. Because it&rsquo;s fast, efficient, and offers tons of cool features, like load balancing and rolling restarts, Unicorn has become a popular production server for Rails apps.</p>

<h1>Comparing Unicorn with Passenger</h1>

<p>When I deployed Phindee for the first time, however, I actually used the open source version of <a href="https://www.phusionpassenger.com/">Phusion Passenger</a>, due to the fact that it was (and is) easier to setup than Unicorn. My main concern, at the time, was to have a functioning app deployed as soon as possible, with as little effort as possible, and Passenger helped me do just that.</p>

<p>Eventually, I reached a point where I was ready for something that I could configure myself, and Unicorn seemed like a good next step. But if you’re a beginner, Passenger will be the easiest to start with since it’s designed to integrate into Nginx directly and, therefore, requires less work to setup and maintain. You will have to pay for the Enterprise version, however, if you want advanced features like error-resistant, zero-downtime deploys, which come for free with Unicorn.</p>

<h2>Do One Thing, Do It Well</h2>

<p>The reason why I like Unicorn is due to its philosophy of doing a few things well. An example of this is load balancing, which Unicorn hands off to the operating system entirely. When Unicorn starts, its master process spawns (forks) a configured number of processes called workers. These workers then handle the incoming requests to your app and only accept a request when they’re ready.</p>

<p>But it’s the operating system that handles the forking, as well as the distribution of requests between processes that are ready to accept, not Unicorn. What Unicorn does is the actual monitoring of workers themselves through the master process. If a worker, for example, takes too much time to complete a task, the master process will kill it and spawn a new one.</p>

<h2>Deploys Done Right</h2>

<p>What this design can achieve is error-resistant, zero-downtime deploys. Error-resistant deploys ensure that if something goes wrong during a deploy, your app will remain online and serve incoming requests using the old code. This is possible because Unicorn doesn’t kill off old workers until new workers have successfully forked, which means your old workers will stay alive if something goes wrong with the new ones.</p>

<p>Zero-downtime deploys work in a similar manner. We can send a signal to the master process telling it to start a new master, and this new master will then begin reloading our new code. Once it’s fully loaded, the new master will fork its workers. The first worker forked will notice there is still an old master running, and it’ll send a signal telling it to start gracefully shutting down its workers. When all workers finish serving their current requests, the old master then dies, and our app is fully reloaded with new code.</p>

<p>Passenger supports rolling restarts like this as well, but they only come with the paid Passenger Enterprise version. One advantage the Enterprise version provides, however, is it restarts the processes one-by-one, which requires less memory. Rolling restarts with Unicorn, on the other hand, are done all at once and temporarily require twice the memory usage. It is possible, of course, to script one-by-one rolling restarts in Unicorn, but Passenger does this automatically for you.</p>

<h1>How about Puma?</h1>

<p>Another alternative to Unicorn and Passenger is Puma. Whereas Unicorn and Passenger achieve concurrency through the use of forks, Puma achieves it by running multiple threads in a single process. Of course, this means that your code must be thread-safe, but since Rails 4 is thread-safe by default, this shouldn’t be an issue.</p>

<p>Because threading requires less memory than forking, Puma will be more memory efficient than a similar Unicorn setup. Puma, however, does not do rolling restarts, nor does watch for and restart failed processes, like Unicorn, which means you’ll need a service like <a href="http://mmonit.com/monit/">Monit</a> that monitors and restarts them for you. As with any technology, pick whatever best meets your needs.</p>

<h1>Installing and Configuring Unicorn</h1>

<p>With that out of the way, we’re now ready to start working with Unicorn. We’ll begin by adding the following line to our app’s <code>Gemfile</code> on our local computer:</p>

<p><code>ruby Gemfile
gem 'unicorn', '~&gt; 4.8.0’
</code></p>

<p>Make sure you change the version number to whatever’s the most recent one at the time of your install. The <code>~&gt;</code> notation means that any future minor updates (e.g., from 4.0.0 to 4.0.1) will be installed, but major ones (e.g., from 4.0 to 4.1) won’t be. Major updates can sometimes introduce unexpected behavior in your app, so it’s best to limit the updates to minor releases only.</p>

<p>We&rsquo;ll then install Unicorn by running <code>bundle</code> in the root path of our app, and Bundler, which we installed in <a href="/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/">part 2</a>, will take care of the install for us.</p>

<p>Having Unicorn installed, we can begin configuring it. We’ll start by creating a file called <code>unicorn.rb</code> on our local computer inside the <code>/config</code> directory of our Rails application. This is how my file for Phindee looks:</p>

<p>``` ruby unicorn.rb
root = &ldquo;/var/www/phindee/current&rdquo;
working_directory root
pid &ldquo;#{root}/tmp/pids/unicorn.pid&rdquo;
stderr_path &ldquo;#{root}/log/unicorn.log&rdquo;
stdout_path &ldquo;#{root}/log/unicorn.log&rdquo;</p>

<p>listen &ldquo;/tmp/unicorn.phindee.sock&rdquo;
worker_processes 2
timeout 30
```</p>

<p>The first variable <code>root</code> represents the path to the root directory of our app, which I&rsquo;ve set to <code>/var/www/phindee/current</code>. Generally, web apps are stored inside <code>/var/www</code> on Unix since the <code>/var</code> directory is designated for files that increase in size over time, which is the case with most web apps, and a <code>/www</code> directory is typically created inside <code>/var</code> to store files meant for the web. I then have a <code>/phindee</code> directory specified inside <code>/www</code> to store all things related to Phindee, as well as a <code>current</code> directory, which Capistrano will later create and use to store the latest deployment code. You don&rsquo;t have to actually create these directories now, as Capistrano we&rsquo;ll create them itself when it runs.</p>

<p>Below is what the rest of the configurations mean:</p>

<ul>
<li><p><code>working_directory</code> specifies exactly what is says&mdash;the app’s working directory&mdash; and it’s set to the variable <code>root</code>, which we just defined.</p></li>
<li><p><code>pid</code> specifies the path to a <code>.pid</code> file that will store the process ID of Unicorn’s master process, which can be later used to stop the process itself. These files are typically stored inside the <code>/tmp</code> directory since they exist only while Unicorn is running, so you can leave this line the way it is.</p></li>
<li><p><code>stderr_path</code> and <code>stdout_path</code> specify the path to <code>stderr</code> and <code>stdout</code>. If you’re not familiar with what they mean, when a Unix program starts up, it has three streams opened for it: one for input called “standard input” (abbreviated <code>stdin</code>), one for output called “standard output” (abbreviated <code>stdout</code>), and one for printing error messages called “standard error” (abbreviated <code>stderr</code>). Given our configuration, this means that any error messages written by our Rails app to the <code>stderr</code> stream will get written to the <code>.log</code> file specified in the <code>stderr_path</code>. It’s common to point <code>stdout_path</code> to the same location as <code>stderr_path</code> and store them both inside the <code>/log</code> directory.</p></li>
<li><p><code>listen</code> specifies the path to a socket that will listen for a client wanting to make a connection request. If you’re unfamiliar with this, a socket is basically a software object consisting of a port number that’s attached to an IP address. It allows clients and servers to communicate with one another by writing to and reading from their sockets. Since they’re running only when Unicorn is running, they’re usually stored inside the <code>/tmp</code> directory as well.</p></li>
<li><p><code>worker_processes</code> specifies the number of workers that the master process will fork for client request handling. The more workers you set, the more memory you’ll need, and since I don’t have a large amount of memory on my VPS, I decided to set mine to two. This should be enough for a low-traffic app, but once your traffic rises, the number of workers, as well as the amount of memory available to your server, will need to rise with it.</p></li>
<li><p><code>timeout</code> specifies the maximum number of seconds a worker can take to respond to a request before the master kills it and forks a new one. 30 seconds is a good value to put here since whenever a worker takes longer than this to respond, it’s usually safe to assume there is something wrong with the worker itself.</p></li>
</ul>


<p>You can get a complete list of all the other possible configuration options by taking a look Unicorn’s <a href="http://unicorn.bogomips.org/Unicorn/Configurator.html">Configurator Module</a>.</p>

<h1>Managing Unicorn Processes</h1>

<p>Having Unicorn configured, we’ll now need to setup a way for us to manage the Unicorn processes themselves.</p>

<p>Unicorn uses signals to communicate with its processes, and you can find a full explanation of all the available signals <a href="http://unicorn.bogomips.org/SIGNALS.html">here</a>. But sending these signals manually would be a pain. I recommend using a <a href="https://github.com/railscasts/335-deploying-to-a-vps/blob/master/blog-nginx/config/unicorn_init.sh">script on GitHub</a> to automate this process for you. Go ahead and create your own <code>unicorn_init.sh</code> file inside your app’s <code>/config</code> directory and copy/paste the script’s code into it.</p>

<p>All the variables you can change are defined at the beginning of the script. You&rsquo;ll need to set the <code>APP_ROOT</code> variable to the same path that the <code>root</code> variable in <code>unicorn.rb</code> is set to, and you&rsquo;ll want to set the <code>AS_USER</code> variable to the user you set up your server with in <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>. Lastly, you&rsquo;ll want to modify the <code>CMD</code> variable by adding <code>~/.rbenv/bin/rbenv exec</code> right after <code>cd $APP_ROOT;</code>, but right before <code>bundle exec unicorn ...</code>, which is necessary so that the correct environment variables are set when we run the command remotely through Capistrano.</p>

<p>If you’re inside the root directory of your Rails app, you can then make the script executable with the following command:</p>

<p><code>bash
chmod +x config/unicorn_init.sh
</code></p>

<p>I’d like to point out that the way <code>unicorn.rb</code> and <code>unicorn_init.sh</code> is currently setup, Unicorn won’t be doing rolling restarts. If you look at <code>unicorn_init.sh</code>, for example, you’ll notice that it sends a <code>HUP</code> signal when you run the script’s <code>restart</code> command. This signal doesn’t spawn a new master process, the way a rolling restart would do; it simply reloads the <code>unicorn.rb</code> file and gracefully restarts all the workers using the same master process.</p>

<p>You’d need to use the <code>USR2</code> signal for a rolling restart (which is actually what happens when you run the script’s <code>upgrade</code> command). But even then, there are still additional steps you’ll need to take to make everything runs smoothly, like making sure your database connections carry over, as well as ensuring any changes to the database are compatible with the older code.</p>

<p>I won’t be explaining how to do this here because I haven’t yet set it up myself, but if you’re curious, there is a good <a href="http://www.justinappears.com/blog/2-no-downtime-deploys-with-unicorn/">blog post</a> explaining all the nuances you need to be aware of. Phindee is currently a small, low-traffic app and its code is reloaded within seconds, so I’m not worried about users waiting for their requests and don’t see a need for rolling restarts at the moment, but I’m hoping the need presents itself soon.</p>

<p>Having configured Unicorn, we&rsquo;ll move on to configuring Nginx in <a href="/blog/2014/03/27/deploying-rails-apps-part-4-configuring-nginx/">part 4</a>. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and the post will be delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Rails Apps, Part 2: Setting up the Server]]></title>
    <link href="http://vladigleba.github.io/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server/"/>
    <updated>2014-03-14T09:45:00-07:00</updated>
    <id>http://vladigleba.github.io/blog/2014/03/14/deploying-rails-apps-part-2-setting-up-the-server</id>
    <content type="html"><![CDATA[<p>In <a href="/blog/2014/03/05/deploying-rails-apps-part-1-securing-the-server/">part 1</a>, I talked about choosing a VPS provider, creating a new Ubuntu instance, and configuring it to be more secure. Now, in part 2, I&rsquo;ll talk about installing the technology stack behind <a href="http://phindee.com/">Phindee</a>: Node.js, Nginx, PostgreSQL, rbenv, Ruby, and Bundler.</p>

<!-- more -->


<h1>But First!</h1>

<p>Before we proceed any further, make sure you’re logged in as the user you created in part 1; if you’re already logged in as <code>root</code>, you can switch to the correct user with the following command:</p>

<p><code>bash
su - username
</code></p>

<p>Once logged in, we’ll run the following command to fetch the latest updates for the packages on our system:</p>

<p><code>bash
sudo apt-get update
</code></p>

<p>We’ll follow this up with the command to install the necessary package updates:</p>

<p><code>bash
sudo apt-get upgrade
</code></p>

<p>If the command found any updates to install, it will ask if you want to continue with the install; you can enter “y” to do so. Once it finishes, we’ll be ready begin.</p>

<h1>Setting Timezones and Installing Mail</h1>

<p>We’ll start by setting the correct timezone:</p>

<p><code>bash
sudo dpkg-reconfigure tzdata
</code></p>

<p>You’ll be asked to choose your country and timezone, after which your server’s local time will be displayed; if it displays the correct time, you’re good to go.</p>

<p>We’ll install <code>postfix</code> and <code>telnet</code> next to enable our Rails app to send email:</p>

<p><code>bash
sudo apt-get -y install telnet postfix
</code></p>

<p>Feel free to just press “enter” through all the prompts and keep all the defaults.</p>

<p>Next, we’ll install some useful packages we’ll later need, among them <code>python-software-properties</code>, which will allow us to easily add new repositories to the <code>apt</code> package handling system:</p>

<p><code>bash
sudo apt-get -y install curl git-core python-software-properties
</code></p>

<p>Having the ability to add new repositories this way allows us to install the most recent updates since the default <code>apt-get</code> repositories typically don’t receive the latest updates immediately.</p>

<h1>Installing Node.js</h1>

<p>We’ll actually put this ability to use right now by adding a new repository for <a href="http://nodejs.org/">Node.js</a>:</p>

<p><code>bash
sudo add-apt-repository ppa:chris-lea/node.js
</code></p>

<p>We’ll then update the created repository with the latest Node.js code available:</p>

<p><code>bash
sudo apt-get -y update
</code></p>

<p>and install it, like so:</p>

<p><code>bash
sudo apt-get -y install nodejs
</code></p>

<p>We could’ve avoided adding a new repo and just used the traditional <code>apt-get</code> method to do the install, but this would’ve installed an older version of Node.js. Because Node.js is under active development and things are added quite frequently, it’s important to run the latest possible version. This might not matter as much for software that doesn’t have an aggressive update schedule, but this is the route we’ll take for Node.js.</p>

<p>By the way, if you’re wondering why we’re installing Node.js, the reason is it provides a good way to execute JavaScript, and we’ll need this for the Rails <a href="http://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>.</p>

<h1>Installing Nginx</h1>

<p>Next, we’ll install a web server called <a href="http://wiki.nginx.org/Main">Nginx</a>, which will handle all our static requests, such as stylesheets, scripts, images, and fonts. Its low memory usage and ability to serve static content quickly and efficiently make it a popular alternative to Apache and an excellent choice for sites running on a Virtual Private Server (VPS). What makes Nginx efficient is the fact that it’s an event-based server, while Apache, on the other hand, is process-based. An event-based server doesn&rsquo;t spawn new processes or threads for each request the way a process-based one does, and this means lower memory usage and faster responses.</p>

<p>We’ll install it by adding another repository:</p>

<p><code>bash
sudo add-apt-repository ppa:nginx/stable
sudo apt-get -y update
sudo apt-get -y install nginx
</code></p>

<p>Once it’s installed, we can start it up with:</p>

<p><code>bash
sudo service nginx start
</code></p>

<p>If you now visit your server’s IP address, you should see a simple page proclaiming “Welcome to nginx!”</p>

<h1>Installing PostgreSQL</h1>

<p>Most modern apps need to store some sort of data, and there are a plethora of open source databases available, like <a href="https://www.mysql.com/">MySQL</a>, <a href="https://sqlite.org/">SQLite</a>, and <a href="http://www.postgresql.org/">PostgreSQL</a>. I never tried MySQL, but when I first started out, I used SQLite, the default database for Rails apps, because I liked its simplicity and saw no need for something more sophisticated. As my needs have evolved, however, so has my database, and I recently decided to switch to PostgreSQL because of its support for a fast key-value store called HStore and its ability to do full-text search, both of which I&rsquo;ll need for Phindee.</p>

<p>We’ll install it with <code>apt-get</code>:</p>

<p><code>bash
sudo apt-get install postgresql postgresql-contrib libpq-dev
</code></p>

<p>We can then start Postgres as the default <code>postgres</code> user with the following command:</p>

<p><code>bash
sudo -u postgres psql
</code></p>

<p>Had we not specified the default user, it would’ve tried to use the user we’re logged in with on our VPS, and Postgres would’ve complained that the role doesn’t exist since there is no such user created in Postgres. This makes it necessary to login as the default <code>postgres</code> user.</p>

<p>Once logged in, we’ll setup a password for <code>postgres</code>:</p>

<p><code>mysql
\password
</code></p>

<p>We’ll also create a new user called <code>admin</code>, followed by a database called <code>phindee</code>, which will be owned by <code>admin</code>:</p>

<p><code>mysql
create user admin with password 'secret';
create database phindee owner admin;
</code></p>

<p>Having the basics setup, we can now quit Postgres:</p>

<p><code>mysql
\quit
</code></p>

<h1>Installing rbenv</h1>

<p><a href="https://github.com/sstephenson/rbenv">rbenv</a> is a tool that helps you manage the Ruby versions installed on your system, thereby allowing you to easily switch between them. Whenever you want to play with a new version of Rails&mdash;without messing up your current setup&mdash;rbenv will come in handy.</p>

<p>You may be familiar with another Ruby version manager called <a href="https://rvm.io/">RVM</a>. I used it myself for a while, before switching over to rbenv. It’s not that one is “better” than the other; it’s about which one is better suited for <em>your</em> needs. I made the switch because rbenv is more lightweight than RVM, its design feels cleaner, and it has a cool name.</p>

<p>rbenv will suite you well if you’re starting out; otherwise, install whatever best meets your needs. By the way, it’s worth mentioning that since rbenv is incompatible with RVM, you won’t be able to run them side by side.</p>

<p>All right, we can install rbenv like so:</p>

<p><code>bash
sudo curl -L https://raw.github.com/fesplugas/rbenv-installer/master/bin/rbenv-installer | bash
</code></p>

<p>This will run a script that will do most of the install for us. In the end, you’ll receive a message telling you to add rbenv to the load path, and you can do so by opening up <code>bash_profile</code>:</p>

<p><code>bash
sudo nano ~/.bash_profile
</code></p>

<p>and copying/pasting the code that was outputted by the message. We’ll then need to reload the file for the changes to take effect:</p>

<p><code>bash
. ~/.bash_profile
</code></p>

<p>We’re almost ready to install Ruby, but before we do, we first need to install the C compiler and the Make utility, which is needed for the Ruby install. We can do so by installing a package called <code>build-essential</code>, along with some additional packages we’ll need later on:</p>

<p><code>bash
sudo apt-get install zlib1g-dev build-essential libssl-dev libreadline-dev libyaml-dev libsqlite3-dev sqlite3 libxml2-dev libxslt1-dev
</code></p>

<p>With the packages installed, we’re now ready to install Ruby itself.</p>

<h1>Installing Ruby</h1>

<p>To see a list of all the Ruby versions available, we can run the following command:</p>

<p><code>bash
rbenv install --list
</code></p>

<p>I chose to install version 2.1.0, as that was the latest one at the time:</p>

<p><code>bash
rbenv install 2.1.0
</code></p>

<p>This will take a few minutes to run&mdash;and that’s probably an understatement&mdash;but once it finishes, we’ll make the version it just installed the default Ruby version on our server:</p>

<p><code>bash
rbenv global 2.1.0
</code></p>

<p>If everything finished successfully, typing <code>ruby -v</code> should output the Ruby version we now have installed.</p>

<h1>Installing Bundler</h1>

<p>If you’ve never used it before, <a href="http://bundler.io/">Bundler</a> is a tool that helps you easily manage and install gems (Ruby programs and libraries). It allows you to specify the gems your app relies on, along with their versions, and Bundler will then install them all for you, in addition to automatically installing and managing any dependencies (other gems) they rely on.</p>

<p>It’s usually a good idea to include version numbers for your gems because new versions can sometimes introduce changes that cause the old features you rely on to behave differently, which can result in errors the next time you try to run your app. By using Bundler to specify not only the gems you need, but also the versions of those gems, you can save yourself from needless headaches (and unnecessary cups of coffee).</p>

<p>We will install bundler with the following command:</p>

<p><code>bash
gem install bundler --no-ri --no-rdoc
</code></p>

<p>Every time we install a gem that provides us with commands we can execute, we’ll need to run <code>rbenv rehash</code>, which will give us access to the corresponding executable (<a href="http://stackoverflow.com/questions/9394338/how-do-rvm-and-rbenv-actually-work">see this page</a> to learn why this is so). Since Bundler is one of these gems, we’ll do the rehash next:</p>

<p><code>bash
rbenv rehash
</code></p>

<p>If things installed successfully, <code>bundle -v</code> should return the Bundler version that was just installed.</p>

<p>As an aside, notice that we’re specifying the <code>—no-ri</code> and <code>—no-rdoc</code> flags to avoid installing the gem’s documentation, which often takes longer than the gem installation itself and is typically unnecessary, especially on a production server. But typing out these flags for each and every gem you install will give you <a href="http://www.webmd.com/pain-management/carpal-tunnel/carpal-tunnel-syndrome-topic-overview">carpel tunnel</a> sooner than you&rsquo;d like, so its best to create a <code>.gemrc</code> file in your home directory:</p>

<p><code>bash
nano ~/.gemrc
</code></p>

<p>and add the following line into it:</p>

<p><code>text
gem: --no-rdoc --no-ri
</code></p>

<p>The flags will then be included automatically the next time you install new gems.</p>

<p>And with that, our server setup is now complete! Having installed Node.js, Nginx, PostgreSQL, and rbenv, we’re now ready to start configuring Nginx and Unicorn, which I’ll cover in the <a href="/blog/2014/03/21/deploying-rails-apps-part-3-configuring-unicorn/">next post</a>. If you want to be notified when it’s out, feel free to <a href="http://www.feedblitz.com/f/?Sub=927939&amp;cids=1">subscribe</a>, and you’ll have the complete post delivered to your inbox as soon as it’s released!</p>
]]></content>
  </entry>
  
</feed>
